{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 1: Importar as bibliotecas e o dataset\n",
    "# Como fiz: Nessa etapa eu usei o mesmo modelo do colab e alterei apenas o dataset\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.datasets import fashion_mnist  # Alterei o \"cifar10\" para \"fashion_mnist\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 2: Carregamento de dados\n",
    "# Como fiz: Alterei o modelo do colab para incluir o que estava no dataset\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data() # Alterei o dataset de \"cifar10\" para \"fashion_mnist\"\n",
    "\n",
    "# Mostrando o tamanho do dataset (dimensão)\n",
    "print(\"Dimensões do conjunto de treinamento:\", X_train.shape)\n",
    "print(\"Dimensões do conjunto de teste:\", X_test.shape)\n",
    "\n",
    "# Classes presentes no dataset\n",
    "classes = ['T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'] # Alterei as classes para ficarem correspondentes com o dataset utilizado\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(X_train[i])\n",
    "    plt.title(classes[y_train[i]]) # [y_train], no fashion_mnist, é um vetor de uma dimensão, então o correto seria y_train[i], não y_train[i][0]\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 3: Normalização dos dados\n",
    "# Como fiz: Não fiz alterações do modelo do colab para esse\n",
    "\n",
    "''' Explicação breve de normalização de dados (eu não entendia direito o que era): \n",
    "Ajuda a melhorar o desempenho de modelos de aprendizado de máquina, \n",
    "pois evita que valores muito grandes dominem os cálculos \n",
    "e facilita a convergência durante o treinamento.'''\n",
    "\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# No fashion_mnist, os pixels variam de 0 a 255, ao dividí-los por 255, os valores variam entre a faixa 0 a 1\n",
    "\n",
    "y_train = to_categorical(y_train, 10) # Essa parte não entendi, preciso de uma explicação\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 4: Separação dos dados entre treino e teste\n",
    "# Cada imagem do fashion_mnist é representada por uma matriz de pixels 28x28\n",
    "# Como fiz: Alterei os valores do código original (32, 64, 128) para múltiplos de 28 (pixels do fashion_mnist)\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(56, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(112, (3, 3), activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(112, activation='relu'),\n",
    "    Dropout(0.5),  # Para evitar overfitting\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Terá como saída uma tabela de \"model\"\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 5: Primeiro treino"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
